{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eginpcF4Qll7"
   },
   "source": [
    "### Download VOC 2007 and save it to locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U-nvMdsd50w3"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "root_dir = '/content/data'\n",
    "data_exist = False\n",
    "\n",
    "try:\n",
    "  os.mkdir(root_dir) \n",
    "  os.chdir(root_dir) \n",
    "except:\n",
    "  data_exist = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 362253
    },
    "colab_type": "code",
    "id": "B5eIuV5FoHyI",
    "outputId": "12cff72b-d5c9-4ae4-ec4f-9f49a53818d9"
   },
   "outputs": [],
   "source": [
    "if not data_exist:\n",
    "  !curl -LO \"http://host.robots.ox.ac.uk/pascal/VOC/voc2012/VOCtrainval_11-May-2012.tar\"\n",
    "  !curl -LO \"http://host.robots.ox.ac.uk/pascal/VOC/voc2007/VOCtrainval_06-Nov-2007.tar\"\n",
    "  !curl -LO \"http://host.robots.ox.ac.uk/pascal/VOC/voc2007/VOCtest_06-Nov-2007.tar\"\n",
    "  !tar -xvf \"VOCtrainval_06-Nov-2007.tar\"\n",
    "  !tar -xvf \"VOCtest_06-Nov-2007.tar\"\n",
    "  !tar -xvf \"VOCtrainval_11-May-2012.tar\"\n",
    "  !rm \"VOCtrainval_06-Nov-2007.tar\"\n",
    "  !rm \"VOCtest_06-Nov-2007.tar\"\n",
    "  !rm \"VOCtrainval_11-May-2012.tar\"  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YslcQuEs3_it"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import models\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from net import vgg16, vgg16_bn\n",
    "from resnet_yolo import resnet50, resnet18\n",
    "from yoloLoss import yoloLoss\n",
    "from dataset import yoloDataset\n",
    "\n",
    "from visualizer import Visualizer\n",
    "import time\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8WsPuKcB3_iz"
   },
   "outputs": [],
   "source": [
    "file_root = root_dir +  '/VOCdevkit/VOC2007/JPEGImages/'\n",
    "project_path = '/content/gdrive/My Drive/Colab Notebooks/pytorch-YOLO-v1'\n",
    "learning_rate = 0.001\n",
    "num_epochs = 50\n",
    "batch_size = 24\n",
    "use_resnet = True\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "if use_resnet:\n",
    "    net = resnet50()\n",
    "else:\n",
    "    net = vgg16_bn()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 10914
    },
    "colab_type": "code",
    "id": "aRxk9iz-CRzK",
    "outputId": "eb5189bc-5a14-4755-e253-3c827673b14f"
   },
   "outputs": [],
   "source": [
    "print('load pre-trined model')\n",
    "if use_resnet:\n",
    "    resnet = models.resnet50(pretrained=True)\n",
    "    new_state_dict = resnet.state_dict()\n",
    "    dd = net.state_dict()\n",
    "    for k in new_state_dict.keys():\n",
    "        print(k)\n",
    "        if k in dd.keys() and not k.startswith('fc'):\n",
    "            print('yes')\n",
    "            dd[k] = new_state_dict[k]\n",
    "    net.load_state_dict(dd)\n",
    "else:\n",
    "    vgg = models.vgg16_bn(pretrained=True)\n",
    "    new_state_dict = vgg.state_dict()\n",
    "    dd = net.state_dict()\n",
    "    for k in new_state_dict.keys():\n",
    "        print(k)\n",
    "        if k in dd.keys() and k.startswith('features'):\n",
    "            print('yes')\n",
    "            dd[k] = new_state_dict[k]\n",
    "    net.load_state_dict(dd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LFGj9GV7SGqu"
   },
   "outputs": [],
   "source": [
    "criterion = yoloLoss(7,2,5,0.5)\n",
    "\n",
    "net = net.to(device)\n",
    "net.train()\n",
    "# different learning rate\n",
    "params=[]\n",
    "params_dict = dict(net.named_parameters())\n",
    "for key,value in params_dict.items():\n",
    "    if key.startswith('features'):\n",
    "        params += [{'params':[value],'lr':learning_rate*1}]\n",
    "    else:\n",
    "        params += [{'params':[value],'lr':learning_rate}]\n",
    "optimizer = torch.optim.SGD(params, lr=learning_rate, momentum=0.9, weight_decay=5e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VH38QYvdQvqg"
   },
   "source": [
    "### Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "vKT_B8mn3_jP",
    "outputId": "c3ab3560-e92e-4cdd-fd6f-7dbe273c9ce7"
   },
   "outputs": [],
   "source": [
    "train_dataset = yoloDataset(root=file_root,list_file=[os.path.join(project_path, 'voc2007.txt'), os.path.join(project_path, 'voc2012.txt')],train=True,transform = [transforms.ToTensor()] )\n",
    "train_loader = DataLoader(train_dataset,batch_size=batch_size,shuffle=True,num_workers=4)\n",
    "# test_dataset = yoloDataset(root=file_root,list_file='voc07_test.txt',train=False,transform = [transforms.ToTensor()] )\n",
    "test_dataset = yoloDataset(root=file_root,list_file=os.path.join(project_path, 'voc2007test.txt'),train=False,transform = [transforms.ToTensor()] )\n",
    "test_loader = DataLoader(test_dataset,batch_size=batch_size,shuffle=False,num_workers=4)\n",
    "print('the dataset has %d images' % (len(train_dataset)))\n",
    "print('the batch_size is %d' % (batch_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xyZXftN7QO2L"
   },
   "source": [
    "### Train loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 38794
    },
    "colab_type": "code",
    "id": "0zMG38FV3_jZ",
    "outputId": "df5ba856-85b7-4ced-f2f0-df725d951ae0"
   },
   "outputs": [],
   "source": [
    "num_iter = 0\n",
    "vis = Visualizer()\n",
    "best_test_loss = np.inf\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    net.train()\n",
    "    if epoch == 1:\n",
    "        learning_rate = 0.0005\n",
    "    if epoch == 2:\n",
    "        learning_rate = 0.00075\n",
    "    if epoch == 3:\n",
    "        learning_rate = 0.001\n",
    "    if epoch == 30:\n",
    "        learning_rate=0.0001\n",
    "    if epoch == 40:\n",
    "        learning_rate=0.00001\n",
    "\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = learning_rate\n",
    "    \n",
    "    print('\\n\\nStarting epoch %d / %d' % (epoch + 1, num_epochs))\n",
    "    print('Learning Rate for this epoch: {}'.format(learning_rate))\n",
    "    \n",
    "    total_loss = 0.\n",
    "    \n",
    "    for i,(images,target) in enumerate(train_loader):\n",
    "        images = images.to(device)\n",
    "        target = target.to(device)\n",
    "        pred = net(images)\n",
    "        loss = criterion(pred,target)\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if (i+1) % 5 == 0:\n",
    "            print ('Epoch [%d/%d], Iter [%d/%d] Loss: %.4f, average_loss: %.4f' \n",
    "            %(epoch+1, num_epochs, i+1, len(train_loader), loss.item(), total_loss / (i+1)))\n",
    "            num_iter += 1\n",
    "            vis.add_log(epoch, (\"loss_train\", total_loss/(i+1)))\n",
    "\n",
    "    #validation\n",
    "    validation_loss = 0.0\n",
    "    net.eval()\n",
    "    for i,(images,target) in enumerate(test_loader):\n",
    "        images = images.to(device)\n",
    "        target = target.to(device)     \n",
    "        with torch.set_grad_enabled(False):\n",
    "          pred = net(images)\n",
    "          loss = criterion(pred,target)\n",
    "          validation_loss += loss.item()\n",
    "    validation_loss /= len(test_loader)\n",
    "    vis.add_log(epoch, (\"loss_val\", validation_loss))\n",
    "    vis.save(os.path.join(project_path, 'temp.csv'))\n",
    "    if best_test_loss > validation_loss:\n",
    "        best_test_loss = validation_loss\n",
    "        print('get best test loss %.5f' % best_test_loss)\n",
    "        torch.save(net.state_dict(),'best.pth')\n",
    "        \n",
    "\n",
    "    vis.save('train_log{}.csv'.format(time.time()))\n",
    "    torch.save(net.state_dict(),os.path.join(project_path, 'yolo.pth'))\n",
    "    vis.plot()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "train_yolo.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
